ğŸ§  KNN From Scratch in C++ (Classification & Regression)

A fully custom implementation of K-Nearest Neighbors (KNN) written from scratch in C++, designed to work on real Kaggle datasets with proper machine-learning hygiene.

This project implements the entire ML pipeline manually:

CSV parsing

Missing value handling

Feature scaling

Train/test split

Distance metrics

KNN classification & regression

Evaluation metrics

Prediction export for visualization


No ML libraries. No shortcuts.


---

ğŸš€ Features

Core ML

âœ… KNN Classifier

âœ… KNN Regressor

âœ… Euclidean & Manhattan distance

âœ… Deterministic predictions with tie-breaking


Data Handling

âœ… CSV loader from scratch

âœ… Missing value detection (NA, NaN, ?, empty)

âœ… Mean imputation (training data only)

âœ… Target-aware row dropping

âœ… Standard scaling (z-score)


Evaluation

âœ… Accuracy

âœ… Confusion matrix

âœ… RMSE

âœ… MAE


Engineering

âœ… Modular C++ architecture

âœ… CLI-friendly

âœ… Kaggle-scale ready

âœ… Export predictions for visualization

âœ… Linux / Termux compatible



---

ğŸ“‚ Project Structure

knn_cpp/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ winequality.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.cpp
â”‚
â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ csv_reader.cpp
â”‚   â”‚   â””â”€â”€ csv_reader.h
â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.cpp
â”‚   â”‚   â””â”€â”€ dataset.h
â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ imputer.cpp
â”‚   â”‚   â”œâ”€â”€ imputer.h
â”‚   â”‚   â”œâ”€â”€ scaler.cpp
â”‚   â”‚   â””â”€â”€ scaler.h
â”‚
â”‚   â”œâ”€â”€ distance/
â”‚   â”‚   â”œâ”€â”€ distance.cpp
â”‚   â”‚   â””â”€â”€ distance.h
â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ knn_classifier.cpp
â”‚   â”‚   â”œâ”€â”€ knn_classifier.h
â”‚   â”‚   â”œâ”€â”€ knn_regressor.cpp
â”‚   â”‚   â””â”€â”€ knn_regressor.h
â”‚
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ classification_metrics.cpp
â”‚   â”‚   â”œâ”€â”€ regression_metrics.cpp
â”‚   â”‚   â””â”€â”€ metrics.h
â”‚
â”œâ”€â”€ Makefile
â””â”€â”€ README.md


---

ğŸ“Š Dataset

Wine Quality Dataset (Kaggle / UCI)

~6,500 samples

11 numeric features

Target: quality

Used for regression and can be adapted for classification


You can swap in any numeric Kaggle dataset by changing:

CSV path

Target column index



---

âš™ï¸ Build & Run

Requirements

g++ (C++17)

make

Linux / Termux / WSL


Build

make

Run

./knn


---

ğŸ“ˆ Example Output

Loading dataset...
Train samples: 5200
Test samples: 1300
KNN Regression Results
RMSE: 0.68
MAE : 0.52
Predictions saved to predictions.csv


---

ğŸ“‰ Visualising Predictions

Predictions are exported to predictions.csv.

Python (recommended)

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("predictions.csv")

plt.scatter(df.actual, df.predicted, alpha=0.5)
plt.plot([3,9],[3,9],'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("KNN Regression â€“ Wine Quality")
plt.show()


---

ğŸ§ª ML Pipeline (Correct Order)

1. Load CSV


2. Remove rows with missing targets


3. Train/test split


4. Mean imputation (fit on train only)


5. Standard scaling (fit on train only)


6. KNN fit


7. Predict


8. Evaluate



This avoids data leakage and matches industry practice.


---

ğŸ§  Why This Project Matters

Demonstrates low-level ML understanding

Shows correct ML hygiene

Not dependent on sklearn / pandas

Suitable for:

ML systems roles

Data engineering

Performance optimization

Academic ML foundations



---

ğŸ”® Future Extensions

Weighted KNN

KD-Tree / Ball-Tree acceleration

OpenMP multithreading

Classification mode CLI switch

Hyperparameter search

Docker + CI

Benchmark vs sklearn

